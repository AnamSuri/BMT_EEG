{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07376b8b",
   "metadata": {},
   "source": [
    "### BIOMETRIC IDENTIFICATION\n",
    "    Multi-class: Each subject is a unique class\n",
    "    20 neurons (number of subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d124d",
   "metadata": {},
   "source": [
    "    Training data would be from 2 sessions of each subject\n",
    "    Test data would be from 3rd session of each subject\n",
    "    The labels would be from 0 to 19 (20 subjects)\n",
    "    This code is for one task only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32584201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd1b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = ['S1', 'S2', 'S3', 'S4', 'S5',\n",
    "                 'S6','S7', 'S8', 'S9', 'S10',\n",
    "                 'S11', 'S12', 'S13', 'S14', 'S15',\n",
    "                   'S16','S17', 'S18', 'S19', 'S20']\n",
    "\n",
    "training_sessions = ['S1', 'S2']\n",
    "test_session = ['S3']\n",
    "task = 'MI2'\n",
    "\n",
    "lookback = 100\n",
    "path = 'give the path here'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "input_channels = 20\n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "#hidden_size = 128\n",
    "hidden_size = 200\n",
    "\n",
    "#num_epochs = 40\n",
    "num_epochs = 60\n",
    "\n",
    "num_folds = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6bbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create dataset\n",
    "def create_dataset(df, lookback, label):\n",
    "    df = df.to_numpy()\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(df) - lookback + 1, lookback):\n",
    "        X.append(df[i:i + lookback])\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4a030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects to process: ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_all, y_train_all = [], []\n",
    "X_test_all, y_test_all = [], []\n",
    "print(\"Subjects to process:\", all_subjects)\n",
    "\n",
    "for idx, subject in enumerate(all_subjects):\n",
    "    #print(f\"Processing subject: {subject}\")\n",
    "    # Loading training data\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for session in training_sessions:\n",
    "        file_path = os.path.join(path, subject, task, f'{session}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_train = pd.concat([df_train, df], ignore_index=True)\n",
    "    \n",
    "    if 'time' in df_train.columns:\n",
    "        df_train.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    df_train_N = normalize(df_train, norm='max', axis=0)\n",
    "    X_tr, y_tr = create_dataset(pd.DataFrame(df_train_N), lookback, label=idx)\n",
    "    X_train_all.append(X_tr)\n",
    "    y_train_all.append(y_tr)\n",
    "    \n",
    "    for session in test_session:\n",
    "        file_path = os.path.join(path, subject, task, f'{session}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_test = pd.concat([df_test, df], ignore_index=True)\n",
    "    \n",
    "    if 'time' in df_test.columns:\n",
    "        df_test.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    df_test_N = normalize(df_test, norm='max', axis=0)\n",
    "    X_te, y_te = create_dataset(pd.DataFrame(df_test_N), lookback, label=idx)\n",
    "    X_test_all.append(X_te)\n",
    "    y_test_all.append(y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08924752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all training and test data\n",
    "X_train_all = np.concatenate(X_train_all, axis=0)\n",
    "X_test_all = np.concatenate(X_test_all, axis=0)\n",
    "y_train_all = np.concatenate(y_train_all, axis=0)\n",
    "y_test_all = np.concatenate(y_test_all, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cba891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution: [256 256 256 256 256 256 256 256 256 256 256 256 256 256 256 256 256 256\n",
      " 256 256]\n",
      "Test label distribution: [128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label distribution:\", np.bincount(y_train_all))\n",
    "print(\"Test label distribution:\", np.bincount(y_test_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7cf15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes:\n",
      "X_train_all: (5120, 100, 20)\n",
      "y_train_all: (5120,)\n",
      "X_test_all: (2560, 100, 20)\n",
      "y_test_all: (2560,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final shapes:\")\n",
    "print(\"X_train_all:\", X_train_all.shape)\n",
    "print(\"y_train_all:\", y_train_all.shape)\n",
    "print(\"X_test_all:\", X_test_all.shape)\n",
    "print(\"y_test_all:\", y_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901247a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train = torch.tensor(X_train_all).float()\n",
    "y_train = torch.tensor(y_train_all).long()\n",
    "X_test = torch.tensor(X_test_all).float()\n",
    "y_test = torch.tensor(y_test_all).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c90bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([5120, 100, 20])\n",
      "y_train shape: torch.Size([5120])\n",
      "X_test shape: torch.Size([2560, 100, 20])\n",
      "y_test shape: torch.Size([2560])\n"
     ]
    }
   ],
   "source": [
    "### Printing the shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fafc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    return train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c9b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loop\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) \n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    return val_loss, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "271ff6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EEGCNN_GRU(nn.Module):\n",
    "    def __init__(self, input_channels, sequence_length, hidden_size, num_classes):\n",
    "        super(EEGCNN_GRU, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        # self.conv2 = nn.Conv1d(64, 64, 3)\n",
    "        # self.bn2 = nn.BatchNorm1d(64)\n",
    "        # self.conv3 = nn.Conv1d(64, 64, 3)\n",
    "        # self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.maxpool = nn.MaxPool1d(2)\n",
    "        self.gru = nn.GRU(64, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # print(x.shape)\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        # x = F.elu(self.bn2(self.conv2(x)))\n",
    "        # x = F.elu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529f0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = EEGCNN_GRU(input_channels, sequence_length, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training metrics and variables\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "    # K-fold cross-validation within the training set\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train[train_index], y_train[train_index]\n",
    "    X_val_fold, y_val_fold = X_train[val_index], y_train[val_index]\n",
    "\n",
    "    train_loader_fold = DataLoader(TensorDataset(X_train_fold, y_train_fold), batch_size=batch_size, shuffle=True)\n",
    "    val_loader_fold = DataLoader(TensorDataset(X_val_fold, y_val_fold), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_loader_fold, optimizer, criterion, device)\n",
    "        val_loss, val_accuracy = validate(model, val_loader_fold, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "avg_train_loss = np.mean(train_losses)\n",
    "avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "# Plot and save training/validation accuracies and losses\n",
    "os.makedirs(f\"results_identification_{task}\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig(f\"results_identification_{task}/accuracy_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(f\"results_identification_{task}/loss_curve_subject.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26791fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for testing\n",
    "model.load_state_dict(best_model_state_dict)\n",
    "torch.save(model.state_dict(), f'results_identification_{task}/{task}_model.pth')\n",
    "model.eval()\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37111b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluate model ---\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# --- Evaluation metrics ---\n",
    "accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "print(f\"\\nIdentification Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712631a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"avg_train_accuracy\": avg_train_accuracy,\n",
    "    \"avg_val_accuracy\": avg_val_accuracy,\n",
    "    \"avg_train_loss\": avg_train_loss,\n",
    "    \"avg_val_loss\": avg_val_loss,\n",
    "    \"test_accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(f'results_identification_{task}/{task}_metrics.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b67255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_names = [f\"S{i+1}\" for i in range(20)]\n",
    "# --- Confusion Matrix ---\n",
    "conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Subject Identification\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"results_identification_{task}/{task}_cf.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "455b7ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall metrics saved to 'overall_metrics.csv'\n",
      "Per-class metrics saved to 'per_class_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_preds, labels=list(range(20)), target_names=target_names, zero_division=0, output_dict=True)\n",
    "# --- Save Per-Class Metrics to CSV ---\n",
    "df_class_report = pd.DataFrame(report).transpose()\n",
    "df_class_report.to_csv(f\"results_identification_{task}/{task}_per_class_metrics.csv\")\n",
    "\n",
    "print(\"Overall metrics saved to 'overall_metrics.csv'\")\n",
    "print(\"Per-class metrics saved to 'per_class_metrics.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anam_venv_feb2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
